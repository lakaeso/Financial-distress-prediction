{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from utils import remove_top_quantile\n",
    "\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('../data/GiveMeSomeCredit-training.csv')\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "# impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "columns = df.columns\n",
    "index = df.index    \n",
    "df = pd.DataFrame(imputer.fit_transform(df))\n",
    "df.columns = columns\n",
    "df.index = index\n",
    "\n",
    "# outlier removal\n",
    "df = remove_top_quantile(df, \"RevolvingUtilizationOfUnsecuredLines\", 0.99)\n",
    "df = remove_top_quantile(df, \"DebtRatio\", 0.99)\n",
    "df = remove_top_quantile(df, \"MonthlyIncome\", 0.99)\n",
    "\n",
    "# feature engineering\n",
    "def f(a):\n",
    "    # never late\n",
    "    if a[\"NumberOfTime30-59DaysPastDueNotWorse\"] == 0 and \\\n",
    "        a[\"NumberOfTime60-89DaysPastDueNotWorse\"] == 0 and \\\n",
    "        a[\"NumberOfTimes90DaysLate\"] == 0:\n",
    "            return 0\n",
    "    # 30-59 late\n",
    "    if a[\"NumberOfTime30-59DaysPastDueNotWorse\"] != 0 and \\\n",
    "        a[\"NumberOfTime60-89DaysPastDueNotWorse\"] == 0 and \\\n",
    "        a[\"NumberOfTimes90DaysLate\"] == 0:\n",
    "            return 1\n",
    "    # 60-89 late\n",
    "    if a[\"NumberOfTime30-59DaysPastDueNotWorse\"] != 0 and \\\n",
    "        a[\"NumberOfTime60-89DaysPastDueNotWorse\"] != 0 and \\\n",
    "        a[\"NumberOfTimes90DaysLate\"] == 0:\n",
    "            return 2\n",
    "    # 90+ late\n",
    "    return 3\n",
    "\n",
    "\n",
    "df[\"PastDueSevereness\"] = df.apply(f, axis=1)\n",
    "\n",
    "# drop\n",
    "df = df.drop([\"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTime30-59DaysPastDueNotWorse\"], axis=1)\n",
    "\n",
    "# scaling\n",
    "scaler = StandardScaler()\n",
    "df[['age',\n",
    "    'NumberOfDependents',\n",
    "    'MonthlyIncome',\n",
    "    'DebtRatio', \n",
    "    'RevolvingUtilizationOfUnsecuredLines', \n",
    "    'NumberOfOpenCreditLinesAndLoans', \n",
    "    'NumberRealEstateLoansOrLines'\n",
    "]] = scaler.fit_transform(\n",
    "    df[['age',\n",
    "        'NumberOfDependents',\n",
    "        'MonthlyIncome',\n",
    "        'DebtRatio', \n",
    "        'RevolvingUtilizationOfUnsecuredLines', \n",
    "        'NumberOfOpenCreditLinesAndLoans', \n",
    "        'NumberRealEstateLoansOrLines'\n",
    "    ]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_test = pd.read_csv('../data/GiveMeSomeCredit-eval.csv')\n",
    "df_test = df_test.drop([\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "# impute\n",
    "columns = df_test.columns\n",
    "index = df_test.index    \n",
    "df_test = pd.DataFrame(imputer.transform(df_test))\n",
    "df_test.columns = columns\n",
    "df_test.index = index\n",
    "\n",
    "# apply new feature\n",
    "df_test[\"PastDueSevereness\"] = df_test.apply(f, axis=1)\n",
    "\n",
    "# drop\n",
    "df_test = df_test.drop([\"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTime30-59DaysPastDueNotWorse\"], axis=1)\n",
    "\n",
    "# scale\n",
    "df_test[['age',\n",
    "    'NumberOfDependents',\n",
    "    'MonthlyIncome',\n",
    "    'DebtRatio', \n",
    "    'RevolvingUtilizationOfUnsecuredLines', \n",
    "    'NumberOfOpenCreditLinesAndLoans', \n",
    "    'NumberRealEstateLoansOrLines'\n",
    "]] = scaler.transform(\n",
    "    df_test[['age',\n",
    "        'NumberOfDependents',\n",
    "        'MonthlyIncome',\n",
    "        'DebtRatio', \n",
    "        'RevolvingUtilizationOfUnsecuredLines', \n",
    "        'NumberOfOpenCreditLinesAndLoans', \n",
    "        'NumberRealEstateLoansOrLines'\n",
    "    ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into input and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[[\n",
    "    \"RevolvingUtilizationOfUnsecuredLines\",\n",
    "    \"age\",\t\n",
    "    \"DebtRatio\",\t\n",
    "    \"MonthlyIncome\",\t\n",
    "    \"NumberOfOpenCreditLinesAndLoans\",\t\n",
    "    \"NumberRealEstateLoansOrLines\", \n",
    "    \"NumberOfDependents\", \t\n",
    "    \"PastDueSevereness\"\n",
    "]]\n",
    "\n",
    "y_train = df[[\"SeriousDlqin2yrs\"]]\n",
    "\n",
    "X_test = df_test[[\n",
    "    \"RevolvingUtilizationOfUnsecuredLines\",\n",
    "    \"age\",\t\n",
    "    \"DebtRatio\",\t\n",
    "    \"MonthlyIncome\",\t\n",
    "    \"NumberOfOpenCreditLinesAndLoans\",\t\n",
    "    \"NumberRealEstateLoansOrLines\", \n",
    "    \"NumberOfDependents\", \t\n",
    "    \"PastDueSevereness\"\n",
    "]]\n",
    "\n",
    "y_test = df_test[[\"SeriousDlqin2yrs\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight=\"balanced\"),\n",
    "    'Random Forest': RandomForestClassifier(class_weight=\"balanced\"),\n",
    "    'Decision Tree' : DecisionTreeClassifier(class_weight=\"balanced\")\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'Logistic Regression': {'C': [0.001, 0.01, 0.1, 1]},\n",
    "    'Random Forest': {'n_estimators': [10, 15], 'max_depth': [5, 10]},\n",
    "    'Decision Tree':{'max_depth': [5, 10],'criterion':['gini']}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "        \n",
    "    grid_search = GridSearchCV(model, param_grid=param_grids[model_name], cv=cv)\n",
    "\n",
    "    # Fit the grid search on the training data\n",
    "    print(f\"... Fitting {model_name} with params\\n... \\t{param_grids[model_name]}\")\n",
    "    grid_search.fit(X_train, y_train[\"SeriousDlqin2yrs\"])\n",
    "\n",
    "    # Perform cross-validation using the best estimator found by grid search\n",
    "    y_pred_test = cross_val_predict(grid_search.best_estimator_, X_test, y_test[\"SeriousDlqin2yrs\"], cv=cv)\n",
    "\n",
    "    # Calculate accuracy, precision, recall and F1 score\n",
    "    accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    precision = precision_score(y_test, y_pred_test)\n",
    "    recall = recall_score(y_test, y_pred_test)\n",
    "    f1 = f1_score(y_test, y_pred_test)\n",
    "\n",
    "    # save results\n",
    "    results[model_name] = {\n",
    "        'best_params': grid_search.best_params_, \n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print best model\n",
    "Find the best model by F1 score on valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = max(results, key=lambda key: results[key]['f1'])\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Best parameter: {results[best_model_name]['best_params']}\")\n",
    "print(f\"Accuracy: {results[best_model_name]['accuracy']}\")\n",
    "print(f\"Precision: {results[best_model_name]['precision']}\")\n",
    "print(f\"Recall: {results[best_model_name]['recall']}\")\n",
    "print(f\"F1: {results[best_model_name]['f1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "There seems to be no easy answer to which model to choose. Best model I've found is a Random Forest classifier which achieves high accuracy and balanced, but low, precision and recall scores.\n",
    "\n",
    "The real challenge is up to the team which decides uppon rules of credit allocations. You can always give out loans to every customer you have, but that doesn't mean they will pay it back. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

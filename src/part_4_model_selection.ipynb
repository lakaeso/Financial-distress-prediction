{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from utils import remove_top_quantile\n",
    "\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('../data/GiveMeSomeCredit-training.csv')\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "# impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "columns = df.columns\n",
    "index = df.index    \n",
    "df = pd.DataFrame(imputer.fit_transform(df))\n",
    "df.columns = columns\n",
    "df.index = index\n",
    "\n",
    "# outlier removal\n",
    "df = remove_top_quantile(df, \"RevolvingUtilizationOfUnsecuredLines\", 0.99)\n",
    "df = remove_top_quantile(df, \"DebtRatio\", 0.99)\n",
    "df = remove_top_quantile(df, \"MonthlyIncome\", 0.99)\n",
    "\n",
    "# feature engineering\n",
    "def f(a):\n",
    "    # never late\n",
    "    if a[\"NumberOfTime30-59DaysPastDueNotWorse\"] == 0 and \\\n",
    "        a[\"NumberOfTime60-89DaysPastDueNotWorse\"] == 0 and \\\n",
    "        a[\"NumberOfTimes90DaysLate\"] == 0:\n",
    "            return 0\n",
    "    # 30-59 late\n",
    "    if a[\"NumberOfTime30-59DaysPastDueNotWorse\"] != 0 and \\\n",
    "        a[\"NumberOfTime60-89DaysPastDueNotWorse\"] == 0 and \\\n",
    "        a[\"NumberOfTimes90DaysLate\"] == 0:\n",
    "            return 1\n",
    "    # 60-89 late\n",
    "    if a[\"NumberOfTime30-59DaysPastDueNotWorse\"] != 0 and \\\n",
    "        a[\"NumberOfTime60-89DaysPastDueNotWorse\"] != 0 and \\\n",
    "        a[\"NumberOfTimes90DaysLate\"] == 0:\n",
    "            return 2\n",
    "    # 90+ late\n",
    "    return 3\n",
    "\n",
    "\n",
    "df[\"PastDueSevereness\"] = df.apply(f, axis=1)\n",
    "\n",
    "# drop\n",
    "df = df.drop([\"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTime30-59DaysPastDueNotWorse\"], axis=1)\n",
    "\n",
    "# scaling\n",
    "scaler = StandardScaler()\n",
    "df[['age',\n",
    "    'NumberOfDependents',\n",
    "    'MonthlyIncome',\n",
    "    'DebtRatio', \n",
    "    'RevolvingUtilizationOfUnsecuredLines', \n",
    "    'NumberOfOpenCreditLinesAndLoans', \n",
    "    'NumberRealEstateLoansOrLines'\n",
    "]] = scaler.fit_transform(\n",
    "    df[['age',\n",
    "        'NumberOfDependents',\n",
    "        'MonthlyIncome',\n",
    "        'DebtRatio', \n",
    "        'RevolvingUtilizationOfUnsecuredLines', \n",
    "        'NumberOfOpenCreditLinesAndLoans', \n",
    "        'NumberRealEstateLoansOrLines'\n",
    "    ]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_test = pd.read_csv('../data/GiveMeSomeCredit-eval.csv')\n",
    "df_test = df_test.drop([\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "# impute\n",
    "columns = df_test.columns\n",
    "index = df_test.index    \n",
    "df_test = pd.DataFrame(imputer.transform(df_test))\n",
    "df_test.columns = columns\n",
    "df_test.index = index\n",
    "\n",
    "# apply new feature\n",
    "df_test[\"PastDueSevereness\"] = df_test.apply(f, axis=1)\n",
    "\n",
    "# drop\n",
    "df_test = df_test.drop([\"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTime30-59DaysPastDueNotWorse\"], axis=1)\n",
    "\n",
    "# scale\n",
    "df_test[['age',\n",
    "    'NumberOfDependents',\n",
    "    'MonthlyIncome',\n",
    "    'DebtRatio', \n",
    "    'RevolvingUtilizationOfUnsecuredLines', \n",
    "    'NumberOfOpenCreditLinesAndLoans', \n",
    "    'NumberRealEstateLoansOrLines'\n",
    "]] = scaler.transform(\n",
    "    df_test[['age',\n",
    "        'NumberOfDependents',\n",
    "        'MonthlyIncome',\n",
    "        'DebtRatio', \n",
    "        'RevolvingUtilizationOfUnsecuredLines', \n",
    "        'NumberOfOpenCreditLinesAndLoans', \n",
    "        'NumberRealEstateLoansOrLines'\n",
    "    ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into input and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[[\n",
    "    \"RevolvingUtilizationOfUnsecuredLines\",\n",
    "    \"age\",\t\n",
    "    \"DebtRatio\",\t\n",
    "    \"MonthlyIncome\",\t\n",
    "    \"NumberOfOpenCreditLinesAndLoans\",\t\n",
    "    \"NumberRealEstateLoansOrLines\", \n",
    "    \"NumberOfDependents\", \t\n",
    "    \"PastDueSevereness\"\n",
    "]]\n",
    "\n",
    "y_train = df[[\"SeriousDlqin2yrs\"]]\n",
    "\n",
    "X_test = df_test[[\n",
    "    \"RevolvingUtilizationOfUnsecuredLines\",\n",
    "    \"age\",\t\n",
    "    \"DebtRatio\",\t\n",
    "    \"MonthlyIncome\",\t\n",
    "    \"NumberOfOpenCreditLinesAndLoans\",\t\n",
    "    \"NumberRealEstateLoansOrLines\", \n",
    "    \"NumberOfDependents\", \t\n",
    "    \"PastDueSevereness\"\n",
    "]]\n",
    "\n",
    "y_test = df_test[[\"SeriousDlqin2yrs\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight=\"balanced\"),\n",
    "    'Random Forest': RandomForestClassifier(class_weight=\"balanced\"),\n",
    "    'Decision Tree' : DecisionTreeClassifier(class_weight=\"balanced\")\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'Logistic Regression': {'C': [0.001, 0.01, 0.1, 1]},\n",
    "    'Random Forest': {'n_estimators': [10, 15], 'max_depth': [5, 10]},\n",
    "    'Decision Tree':{'max_depth': [5, 10],'criterion':['gini']}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Fitting Logistic Regression with params\n",
      "... \t{'C': [0.001, 0.01, 0.1, 1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\venvs\\deeplearning\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\venvs\\deeplearning\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Fitting Random Forest with params\n",
      "... \t{'n_estimators': [10, 15], 'max_depth': [5, 10]}\n",
      "... Fitting Decision Tree with params\n",
      "... \t{'max_depth': [5, 10], 'criterion': ['gini']}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "        \n",
    "    grid_search = GridSearchCV(model, param_grid=param_grids[model_name], cv=cv)\n",
    "\n",
    "    # Fit the grid search on the training data\n",
    "    print(f\"... Fitting {model_name} with params\\n... \\t{param_grids[model_name]}\")\n",
    "    grid_search.fit(X_train, y_train[\"SeriousDlqin2yrs\"])\n",
    "\n",
    "    # Perform cross-validation using the best estimator found by grid search\n",
    "    y_pred_test = cross_val_predict(grid_search.best_estimator_, X_test, y_test[\"SeriousDlqin2yrs\"], cv=cv)\n",
    "\n",
    "    # Calculate accuracy, precision, recall and F1 score\n",
    "    accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    precision = precision_score(y_test, y_pred_test)\n",
    "    recall = recall_score(y_test, y_pred_test)\n",
    "    f1 = f1_score(y_test, y_pred_test)\n",
    "\n",
    "    # save results\n",
    "    results[model_name] = {\n",
    "        'best_params': grid_search.best_params_, \n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print best model\n",
    "Find the best model by F1 score on valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Random Forest\n",
      "Best parameter: {'max_depth': 10, 'n_estimators': 10}\n",
      "Accuracy: 0.8904109589041096\n",
      "Precision: 0.3274907749077491\n",
      "Recall: 0.4916897506925208\n",
      "F1: 0.39313399778516056\n"
     ]
    }
   ],
   "source": [
    "best_model_name = max(results, key=lambda key: results[key]['f1'])\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Best parameter: {results[best_model_name]['best_params']}\")\n",
    "print(f\"Accuracy: {results[best_model_name]['accuracy']}\")\n",
    "print(f\"Precision: {results[best_model_name]['precision']}\")\n",
    "print(f\"Recall: {results[best_model_name]['recall']}\")\n",
    "print(f\"F1: {results[best_model_name]['f1']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
